{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4b5734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoshinakamoto/Documents/education/mcgill_cs_2023/2025_FALL/comp545/project/code/visual-cot/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from eval_utils import *\n",
    "from data.data_loader import *\n",
    "import ast\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import tqdm\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROJECT_ROOT = \"/Users/satoshinakamoto/Documents/education/mcgill_cs_2023/2025_FALL/comp545/project/code/visual-cot\"\n",
    "os.chdir(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52e2e15",
   "metadata": {},
   "source": [
    "## SETTING MODEL & API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ff601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting API\n",
    "client = genai.Client(api_key=key)\n",
    "\n",
    "# Setting model\n",
    "MODEL = \"gemini-2.5-pro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea6a64",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def board_to_prompt(board):\n",
    "    # Format the board into string representation\n",
    "    formatted = []\n",
    "    for row in board:\n",
    "        new_row = []\n",
    "        for cell in row:\n",
    "            if cell is None:\n",
    "                new_row.append('.')\n",
    "            else:\n",
    "                new_row.append(str(cell))\n",
    "        formatted.append(new_row)\n",
    "\n",
    "    # Create compact single-quote format for LLM prompt\n",
    "    board_str = \"[ \" + \", \".join(\n",
    "        [\"['\" + \"','\".join(row) + \"']\" for row in formatted]\n",
    "    ) + \" ]\"\n",
    "\n",
    "    return board_str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_prompt(exit, board, fsp_examples):\n",
    "\n",
    "    prompt = f'''You have to solve a 6x6 rush hour puzzle.\n",
    "Your goal is to move the Red car out. \n",
    "On the board, 'R' designates the Red car. \n",
    "The exit is located at {exit}.\n",
    "Here are some few examples. \n",
    "\n",
    "Example 1) \n",
    "Input: {fsp_examples[0][0]}\n",
    "Output: {fsp_examples[0][1]}\n",
    "\n",
    "Example 2) \n",
    "Input: {fsp_examples[1][0]}\n",
    "Output: {fsp_examples[1][1]}\n",
    "\n",
    "Example 3) \n",
    "Input: {fsp_examples[2][0]}\n",
    "Output: {fsp_examples[2][1]}\n",
    "                \n",
    "The following puzzle is the one you have to solve:\n",
    "Input: {board}\n",
    "Remember that the exit is located at {exit} and that you have to move the 'R' car.\n",
    "Provide only the text response with no bolding or formatting and do not include the word \"Output:\"'''\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_request(requests_path, pid, prompt_text, model=MODEL, effort=\"medium\"):\n",
    "\n",
    "    req = {\n",
    "        \"custom_id\": str(pid),\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/responses\",\n",
    "        \"body\": {\n",
    "            \"model\": model,\n",
    "            \"reasoning\": { \"effort\": effort},\n",
    "            \"input\": [\n",
    "                {\"role\": \"user\", \"content\": prompt_text}\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(requests_path, \"a\") as f:\n",
    "        f.write(json.dumps(req) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_request_path(batch_number):\n",
    "    return f\"./eval/results/gpt/few_shots/requests_batch_{batch_number}.jsonl\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_batch_status(batch_id):\n",
    "    print(f\"Polling status for job: {batch_id}\")\n",
    "\n",
    "    while True:\n",
    "        job = client.batches.retrieve(batch_id)\n",
    "        print(\"Current status:\", job.status)\n",
    "\n",
    "        if job.status in [\"completed\", \"failed\", \"expired\", \"cancelled\"]:\n",
    "            break\n",
    "        \n",
    "        time.sleep(60)\n",
    "\n",
    "    print(\"Job finished with status:\", job.status)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def write_batch_output(batch_id, responses_path, batch_number = 1):\n",
    "\n",
    "    print(f\"Writing output of batch ID: {batch_id}\")\n",
    "\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "\n",
    "    print(\"Batch state:\", batch.status)\n",
    "\n",
    "    if batch.status == \"completed\":\n",
    "\n",
    "        output_file_id = batch.output_file_id\n",
    "        print(\"Output file ID:\", output_file_id)\n",
    "\n",
    "        file_bytes = client.files.content(output_file_id).read()\n",
    "\n",
    "        with open(responses_path, \"ab\") as f:\n",
    "            f.write(file_bytes)\n",
    "\n",
    "        print(f\"Saved batch output to responses_{batch_number}.jsonl\")\n",
    "\n",
    "    elif batch.status in [\"failed\", \"expired\"]:\n",
    "        print(f\"Batch {batch_number} with failed or expired.\")\n",
    "        print(batch)\n",
    "\n",
    "    else:\n",
    "        print(\"Batch not done yet:\", batch.status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
